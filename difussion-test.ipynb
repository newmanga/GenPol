{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Hyperparameters\n",
    "timesteps = 1000  # Number of diffusion steps\n",
    "\n",
    "\n",
    "# Beta schedule (linear or cosine)\n",
    "beta_start = 0.0001\n",
    "beta_end = 0.02\n",
    "betas = torch.linspace(beta_start, beta_end, timesteps)\n",
    "\n",
    "# Calculate alpha and cumulative alpha\n",
    "alphas = 1.0 - betas\n",
    "alpha_cumprod = torch.cumprod(alphas, dim=0)\n",
    "alpha_cumprod_prev = torch.cat([torch.tensor([1.0]), alpha_cumprod[:-1]])\n",
    "sqrt_recip_alphas = torch.sqrt(1.0 / alphas)\n",
    "sqrt_alphas_cumprod = torch.sqrt(alpha_cumprod)\n",
    "sqrt_one_minus_alphas_cumprod = torch.sqrt(1. - alpha_cumprod)\n",
    "posterior_variance = betas * (1. - alpha_cumprod_prev) / (1. - alpha_cumprod)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def sample_timestep(x, t):\n",
    "    \"\"\"\n",
    "    Calls the model to predict the noise in the image and returns \n",
    "    the denoised image. \n",
    "    Applies noise to this image, if we are not in the last step yet.\n",
    "    \"\"\"\n",
    "    betas_t = get_index_from_list(betas, t, x.shape)\n",
    "    sqrt_one_minus_alphas_cumprod_t = get_index_from_list(\n",
    "        sqrt_one_minus_alphas_cumprod, t, x.shape\n",
    "    )\n",
    "    sqrt_recip_alphas_t = get_index_from_list(sqrt_recip_alphas, t, x.shape)\n",
    "    \n",
    "    # Call model (current image - noise prediction)\n",
    "    model_mean = sqrt_recip_alphas_t * (\n",
    "        x - betas_t * model(x, t) / sqrt_one_minus_alphas_cumprod_t\n",
    "    )\n",
    "    posterior_variance_t = get_index_from_list(posterior_variance, t, x.shape)\n",
    "    \n",
    "    if t == 0:\n",
    "        return model_mean\n",
    "    else:\n",
    "        noise = torch.randn_like(x)\n",
    "        return model_mean + torch.sqrt(posterior_variance_t) * noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(model, shape):\n",
    "    x = torch.randn(shape)  # Start with noise\n",
    "    for t in reversed(range(timesteps)):\n",
    "        t_tensor = torch.tensor([t])\n",
    "        noise_pred = model(x, t_tensor)\n",
    "        alpha_t = alpha_cumprod[t]\n",
    "        alpha_t_prev = alpha_cumprod_prev[t]\n",
    "        beta_t = betas[t]\n",
    "\n",
    "        # Reverse step\n",
    "        mean = (x - beta_t / torch.sqrt(1 - alpha_t) * noise_pred) / torch.sqrt(alpha_t_prev)\n",
    "        noise = torch.randn_like(x) if t > 0 else 0  # Add noise unless final step\n",
    "        x = mean + torch.sqrt(beta_t) * noise\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class TimestepEmbedding(nn.Module):\n",
    "    def __init__(self, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "    def forward(self, t):\n",
    "        half_dim = self.embedding_dim // 2\n",
    "        # Create frequency bands\n",
    "        freqs = torch.exp(-math.log(10000) * torch.arange(half_dim).float() / half_dim)\n",
    "        angles = t[:, None].float() * freqs[None, :]  # Shape: (batch_size, half_dim)\n",
    "        # Sinusoidal embedding\n",
    "        embedding = torch.cat([torch.sin(angles), torch.cos(angles)], dim=-1)\n",
    "        return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_diffusion(x, t):\n",
    "    noise = torch.randn_like(x)\n",
    "    sqrt_alpha_cumprod = torch.sqrt(alpha_cumprod[t]).view(-1, 1, 1)\n",
    "    sqrt_one_minus_alpha_cumprod = torch.sqrt(1 - alpha_cumprod[t]).view(-1, 1, 1)\n",
    "    return sqrt_alpha_cumprod * x + sqrt_one_minus_alpha_cumprod * noise, noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1,) * (4 - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenoisingModel(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim = 128):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.timestep_embedding = TimestepEmbedding(embedding_dim)\n",
    "\n",
    "        # Model layers\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim + embedding_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, input_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        # Embed the timestep\n",
    "        t_emb = self.timestep_embedding(t)\n",
    "        # Concatenate the timestep embedding with the input\n",
    "        x_t = torch.cat([x, t_emb], dim=-1)\n",
    "        return self.net(x_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diffusion_loss(model, x, t):\n",
    "    noisy_x, noise = forward_diffusion(x, t)\n",
    "    predicted_noise = model(noisy_x, t)\n",
    "    return nn.MSELoss()(predicted_noise, noise)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "epochs = 1\n",
    "\n",
    "# Instantiate the model\n",
    "input_dim = 10  # Example input dimension\n",
    "embedding_dim = 16  # Embedding dimension for timestep\n",
    "model = DenoisingModel(input_dim, embedding_dim)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Random data batch\n",
    "    x = torch.randn(32, input_dim)\n",
    "    t = torch.randint(0, timesteps, (32,))  # Random timesteps\n",
    "\n",
    "    # Compute loss\n",
    "    loss = diffusion_loss(model, x, t)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gan-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
